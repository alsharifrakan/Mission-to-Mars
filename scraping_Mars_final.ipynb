{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Driver [C:\\Users\\alsha\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_title': \"Watch (and Hear) How NASA's Perseverance Rover Took Its First Selfie\", 'news_paragraph': 'The historic image of the rover beside the Mars Helicopter proved to be one of the most complex rover selfies ever taken. Video, with bonus audio, sheds light on the process. ', 'featured_image': 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/image/featured/mars1.jpg', 'facts': '<table border=\"1\" class=\"dataframe table table-bordered table-condensed table-hover\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Mars</th>\\n    </tr>\\n    <tr>\\n      <th>Description</th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Equatorial Diameter:</th>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>Polar Diameter:</th>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Distance:</th>\\n      <td>227,943,824 km (1.38 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Period:</th>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>Surface Temperature:</th>\\n      <td>-87 to -5 °C</td>\\n    </tr>\\n    <tr>\\n      <th>First Record:</th>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>Recorded By:</th>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>', 'hemispheres': [{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}], 'last_modified': datetime.datetime(2021, 6, 26, 11, 15, 39, 19374)}\n"
     ]
    }
   ],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "def scrape_all():\n",
    "   # Initiate headless driver for deployment\n",
    "   \n",
    "    news_title, news_paragraph = mars_news(browser)\n",
    "\n",
    "   # Run all scraping function and store results in dictionary\n",
    "    data = {\n",
    "       \"news_title\": news_title,\n",
    "       \"news_paragraph\": news_paragraph,\n",
    "       \"featured_image\": featured_image(browser),\n",
    "       \"facts\": mars_facts(),\n",
    "       \"hemispheres\": hemispheres(browser),\n",
    "       \"last_modified\": dt.datetime.now()\n",
    "   }\n",
    "   # stop webdriver and return data\n",
    "    browser.quit()\n",
    "    return data\n",
    "\n",
    "## Nasa Mars article scraping\n",
    "def mars_news(browser):\n",
    "    # Visit the mars nasa news site\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    browser.visit(url)\n",
    "\n",
    "    # Optional delay for loading the page\n",
    "    browser.is_element_present_by_css(\"ul.item_list li.slide\", wait_time=1)\n",
    "\n",
    "    # Convert the browser html to a soup object and then quit the browser\n",
    "    html = browser.html\n",
    "    news_soup = soup(html, 'html.parser')\n",
    "\n",
    "    # try/except for error handling\n",
    "    try:\n",
    "        # Scrape the title of the first article\n",
    "        slide_elem = news_soup.select_one('ul.item_list li.slide')\n",
    "        # Use parent elememt to find first 'a' tag and save it\n",
    "        news_title = slide_elem.find('div', class_='content_title').get_text()\n",
    "        # Use the parent element to find the paragraph text\n",
    "        news_p = slide_elem.find('div', class_='article_teaser_body').get_text()\n",
    "    except AttributeError:\n",
    "        return None, None\n",
    "    return news_title, news_p\n",
    "\n",
    "## Nasa JPL Image Scraping\n",
    "def featured_image(browser):\n",
    "    # Visit URL\n",
    "    url = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/index.html'\n",
    "    browser.visit(url)\n",
    "\n",
    "    # Find and click the full image button\n",
    "    full_image_elem = browser.find_by_tag('button')[1]\n",
    "    full_image_elem.click()\n",
    "    # Parse the resulting html with soup\n",
    "    html = browser.html\n",
    "    img_soup = soup(html, 'html.parser')\n",
    "\n",
    "    # try/except error handling\n",
    "    try:\n",
    "        # Find the relative image url\n",
    "        img_url_rel = img_soup.find('img', class_='fancybox-image').get('src')\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "    # Use the base URL to create an absolute URL\n",
    "    img_url = f'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/{img_url_rel}'\n",
    "\n",
    "    return img_url\n",
    "\n",
    "# Mars facts scraping\n",
    "def mars_facts():\n",
    "    # try/except error handling\n",
    "    try:\n",
    "        # use 'read_html' to scrape the facts table into a dataframe\n",
    "        df = pd.read_html('http://space-facts.com/mars/')[0]\n",
    "    except BaseException:\n",
    "        return None\n",
    "\n",
    "    # assign columns and set index\n",
    "    df.columns = ['Description','Mars']\n",
    "    df.set_index('Description', inplace=True)\n",
    "    # convert df into html format, add bootstrap\n",
    "    return df.to_html(classes=\"table table-bordered table-condensed table-hover\")\n",
    "\n",
    "def hemispheres(browser):\n",
    "\n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(url)\n",
    "    # Optional delay for loading the page\n",
    "    browser.is_element_present_by_css(\"ul li\", wait_time=1)\n",
    "\n",
    "    # Create list to hold the url and title list of dicts.\n",
    "    hemisphere_image_urls = []\n",
    "\n",
    "    # Parse the HTML\n",
    "    html = browser.html\n",
    "    mhemi_list = soup(html, 'html.parser')\n",
    "    # find the list of results\n",
    "    items = mhemi_list.find_all('div', class_='item')\n",
    "\n",
    "    base_part_url = 'https://astrogeology.usgs.gov'\n",
    "\n",
    "    for item in items:\n",
    "        url = item.find(\"a\")['href']\n",
    "        browser.visit(base_part_url+url)\n",
    "        # Parse individual hemi page\n",
    "        hemi_item_html = browser.html\n",
    "        hemi_soup = soup(hemi_item_html, 'html.parser')\n",
    "        # Scrape title of hemi\n",
    "        title = hemi_soup.find('h2', class_ = 'title').text\n",
    "        # Scrape URL of JPG image\n",
    "        downloads = hemi_soup.find('div', class_ = 'downloads')\n",
    "        image_url = downloads.find('a')['href']\n",
    "        # append dict to empty list\n",
    "        hemisphere_image_urls.append({\"title\": title, \"img_url\": image_url})\n",
    "\n",
    "    return hemisphere_image_urls\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # if running as script, print scraped data\n",
    "    print(scrape_all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Driver [C:\\Users\\alsha\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "hemis = hemispheres(browser) \n",
    "print(hemis)\n",
    "browser.quit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
